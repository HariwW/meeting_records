## 后端开发-腾讯
### 1.手撕 两个String非数相加


### 2.手撕的进一步
支持小数部分：
思路
1. 分割整数部分和小数部分；

2. 对齐小数位数

### 3.Redis使用了哪些
项目中有写到 “通过 MQTT 协议获取实时国家地震等灾害预警信息，并实时传输传感器数据，基于关系数据库进行多源数据建库管理, 采用**Redis 缓存和阻塞队列**实现高并发数据存储。”

所以回答1提到了用Redis做消息队列

#### 追问1：用Redis做消息队列有什么好处和坏处
我们在项目中评估过 Redis 队列批量入库和使用 MQ 的方案：
Redis 方案实现简单、延迟低，适合高并发但对可靠性要求不那么高的实时场景；
它可以在内存中暂存数据，每累计 1000 条或定时批量写入数据库，极大提升吞吐量。

而 MQ（如 Kafka / RocketMQ）则更偏向于可靠的异步解耦和海量消息场景，支持持久化、消息确认和重放，但引入成本更高、延迟略大。

简单来说：

Redis 更轻量、低延迟；

MQ 更可靠、可扩展性强。

在我们系统里，由于实时传感器数据以秒级更新为主，并发量在万级以内，我们采用 Redis + 批量入库，既能保证性能，又简化系统复杂度。


#### 追问2: 为什么用Redis做消息队列这个选型
为了降低我们数据库的压力，所以选择用Redis，每次攒够1000条就写一次

#### 追问3: Redis作为消息队列的主要缺点
Redis 作为消息队列的主要缺点：

| 缺 点 | 描 述 | 影 响 |
|------|------|------|
| 消息可靠性差 |Redis 数据主要存储在内存中，虽然支持 AOF/RDB 持久化，但并非实时；宕机可能丢数据|无法保证 “消息不丢”|
| 没有消费确认机制（ACK） |使用 List 做队列时，BRPOP 一旦取出消息就删除，若消费者崩溃，消息就丢|无法做到 “至少一次” 消费|
|没有重复投递控制|无offset、无message id管理， 容易重复消费|难以保持幂等|
|缺乏消费分组和广播模型|List 模式只能一对一消费；想实现多消费者消费同一消息，需要手动复制|不支持 pub/sub 可靠队列模型|
|无法持久堆积海量消息|Redis 内存受限，堆积大量未消费数据会撑爆内存|不适合高峰期积压|
|无流控机制|消费者处理慢时，没有 backpressure 控制；消费者增减需要手动管理|不具备负载均衡能力|
|功能不完备|无延迟消息、事务消息、死信队列、重试机制、顺序分区等高级功能|无法应对复杂场景|
|集群消息一致性差|Redis Cluster 的分片模型对队列连续性支持差，List 无法跨节点原子操作|不适合分布式队列|

与专业MQ的对比：

| 功能点     | Redis         | Kafka / RocketMQ   |
| ------- | ------------- | ------------------ |
| 消息可靠性   | 弱（内存+异步AOF）   | 强（顺序落盘+ACK）        |
| 消息重复    | 无控制           | 有 Offset 控制        |
| 消费模式    | 一对一           | 支持一对多、广播、订阅        |
| 消息堆积能力  | 差（内存）         | 强（磁盘）              |
| 消息顺序    | 无序（List可局部有序） | 可控（按 Partition 保序） |
| 消息重放    | 不支持           | 支持                 |
| 延迟/死信队列 | 无             | 有                  |
| 吞吐量     | 高（内存）         | 更高（磁盘顺序写）          |
| 集群能力    | 一般            | 完善                 |

面试可以回答的版本：
Redis 可以充当轻量级的消息队列，比如基于 List 或 Stream 实现简单的异步任务处理，优点是实现简单、性能高、延迟低。
但 Redis 本质上是缓存数据库，不是专业的消息中间件，因此有几个主要缺点：

消息可靠性差，宕机可能丢数据；

没有消费确认（ACK）机制，消费者异常会导致消息丢失；

无法支撑大规模消息堆积（内存受限）；

不支持复杂消费模型（广播、重试、延迟、死信等）；

集群下消息一致性较差。

所以，一般只在数据可靠性要求不高、系统简单、流量中等的场景下使用 Redis 队列；
而在要求消息可靠传递、高可用和可追溯的场景，会选择专业 MQ（如 Kafka、RocketMQ）。

#### 补充1： 对于Redis持久化
AOF持久化的步骤：

1. 命令追加（append）：所有的写命令会追加到 AOF 缓冲区中。

2. 文件写入（write）：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用write函数（系统调用），write将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。
3. 文件同步（fsync）：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向硬盘做同步操作。这一步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行强制硬盘同步，fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。
4. 文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
5. 重启加载（load）：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。

持久化方式有哪些：

1. appendfsync always：主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即会调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。appendfsync 
2. everysec：主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数（系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒）appendfsync 
3. no：主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。

这就意味着，Redis存在丢数据的风险

#### 补充2: 对于MySQL的写入流程
执行一条更新记录的流程如下：

1. 执行器负责具体执行，调用存储引擎接口，通过主键索引树获取id记录，
    - 如果id=1这条记录在buffer pool当中，就返回给执行器更新
    - 如果记录不在buffer pool中，将数据页读到buffer pool中，再返回执行器

2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样:
    - 如果一样的话就不进行后续更新流程。
    - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传InnoDB 层，让 InnoDB 真正的执行更新记录的操作;

3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。

4. InnoDB层开始更新记录，会先更新内存(同时标记为脏页)，然后将记录写到redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。
5. 至此，一条记录更新完了。
6. 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有binlog 刷新到硬盘。
7. 事务提交(为了方便说明，这里不说组提交的过程，只说两阶段提交): 
    - prepare 阶段:将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘;
    - commit 阶段:将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为commit(将事务设置为 commit 状态后，刷入到磁盘 redo log 文件);