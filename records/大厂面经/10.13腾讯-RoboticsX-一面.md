## 后端开发-腾讯
### 1.手撕 两个String非数相加


### 2.手撕的进一步
支持小数部分：
思路
1. 分割整数部分和小数部分；

2. 对齐小数位数

### 3.Redis使用了哪些
项目中有写到 “通过 MQTT 协议获取实时国家地震等灾害预警信息，并实时传输传感器数据，基于关系数据库进行多源数据建库管理, 采用**Redis 缓存和阻塞队列**实现高并发数据存储。”

所以回答1提到了用Redis做消息队列

#### 追问1：用Redis做消息队列有什么好处和坏处
我们在项目中评估过 Redis 队列批量入库和使用 MQ 的方案：
Redis 方案实现简单、延迟低，适合高并发但对可靠性要求不那么高的实时场景；
它可以在内存中暂存数据，每累计 1000 条或定时批量写入数据库，极大提升吞吐量。

而 MQ（如 Kafka / RocketMQ）则更偏向于可靠的异步解耦和海量消息场景，支持持久化、消息确认和重放，但引入成本更高、延迟略大。

简单来说：

Redis 更轻量、低延迟；

MQ 更可靠、可扩展性强。

在我们系统里，由于实时传感器数据以秒级更新为主，并发量在万级以内，我们采用 Redis + 批量入库，既能保证性能，又简化系统复杂度。


#### 追问2: 为什么用Redis做消息队列这个选型
为了降低我们数据库的压力，所以选择用Redis，每次攒够1000条就写一次

#### 追问3: Redis作为消息队列的主要缺点
Redis 作为消息队列的主要缺点：

| 缺 点 | 描 述 | 影 响 |
|------|------|------|
| 消息可靠性差 |Redis 数据主要存储在内存中，虽然支持 AOF/RDB 持久化，但并非实时；宕机可能丢数据|无法保证 “消息不丢”|
| 没有消费确认机制（ACK） |使用 List 做队列时，BRPOP 一旦取出消息就删除，若消费者崩溃，消息就丢|无法做到 “至少一次” 消费|
|没有重复投递控制|无offset、无message id管理， 容易重复消费|难以保持幂等|
|缺乏消费分组和广播模型|List 模式只能一对一消费；想实现多消费者消费同一消息，需要手动复制|不支持 pub/sub 可靠队列模型|
|无法持久堆积海量消息|Redis 内存受限，堆积大量未消费数据会撑爆内存|不适合高峰期积压|
|无流控机制|消费者处理慢时，没有 backpressure 控制；消费者增减需要手动管理|不具备负载均衡能力|
|功能不完备|无延迟消息、事务消息、死信队列、重试机制、顺序分区等高级功能|无法应对复杂场景|
|集群消息一致性差|Redis Cluster 的分片模型对队列连续性支持差，List 无法跨节点原子操作|不适合分布式队列|

与专业MQ的对比：

| 功能点     | Redis         | Kafka / RocketMQ   |
| ------- | ------------- | ------------------ |
| 消息可靠性   | 弱（内存+异步AOF）   | 强（顺序落盘+ACK）        |
| 消息重复    | 无控制           | 有 Offset 控制        |
| 消费模式    | 一对一           | 支持一对多、广播、订阅        |
| 消息堆积能力  | 差（内存）         | 强（磁盘）              |
| 消息顺序    | 无序（List可局部有序） | 可控（按 Partition 保序） |
| 消息重放    | 不支持           | 支持                 |
| 延迟/死信队列 | 无             | 有                  |
| 吞吐量     | 高（内存）         | 更高（磁盘顺序写）          |
| 集群能力    | 一般            | 完善                 |

面试可以回答的版本：
Redis 可以充当轻量级的消息队列，比如基于 List 或 Stream 实现简单的异步任务处理，优点是实现简单、性能高、延迟低。
但 Redis 本质上是缓存数据库，不是专业的消息中间件，因此有几个主要缺点：

消息可靠性差，宕机可能丢数据；

没有消费确认（ACK）机制，消费者异常会导致消息丢失；

无法支撑大规模消息堆积（内存受限）；

不支持复杂消费模型（广播、重试、延迟、死信等）；

集群下消息一致性较差。

所以，一般只在数据可靠性要求不高、系统简单、流量中等的场景下使用 Redis 队列；
而在要求消息可靠传递、高可用和可追溯的场景，会选择专业 MQ（如 Kafka、RocketMQ）。

#### 补充1： 对于Redis持久化
AOF持久化的步骤：

1. 命令追加（append）：所有的写命令会追加到 AOF 缓冲区中。

2. 文件写入（write）：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用write函数（系统调用），write将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。
3. 文件同步（fsync）：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向硬盘做同步操作。这一步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行强制硬盘同步，fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。
4. 文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
5. 重启加载（load）：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。

持久化方式有哪些：

1. appendfsync always：主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即会调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。appendfsync 
2. everysec：主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数（系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒）appendfsync 
3. no：主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。

这就意味着，Redis存在丢数据的风险

#### 补充2: 对于MySQL的写入流程
执行一条更新记录的流程如下：

1. 执行器负责具体执行，调用存储引擎接口，通过主键索引树获取id记录，
    - 如果id=1这条记录在buffer pool当中，就返回给执行器更新
    - 如果记录不在buffer pool中，将数据页读到buffer pool中，再返回执行器

2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样:
    - 如果一样的话就不进行后续更新流程。
    - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传InnoDB 层，让 InnoDB 真正的执行更新记录的操作;

3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。

4. InnoDB层开始更新记录，会先更新内存(同时标记为脏页)，然后将记录写到redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。
5. 至此，一条记录更新完了。
6. 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有binlog 刷新到硬盘。
7. 事务提交(为了方便说明，这里不说组提交的过程，只说两阶段提交): 
    - prepare 阶段:将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘;
    - commit 阶段:将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为commit(将事务设置为 commit 状态后，刷入到磁盘 redo log 文件);

### 4. 为什么Redis集群做不到像MQ这样可以随便扩容呢
1. Redis Cluster分片机制

    Redis Cluster 使用 哈希槽（hash slot） 来分片，固定为 16384 个槽；

    每个 key 根据 CRC16 哈希落到 0~16383 的槽；

    每个节点负责一部分槽（slot range）；

    节点之间通过 slot 映射表 路由请求。

2. 扩容流程

    新增节点后，必须把部分 hash slot 从旧节点 迁移（reshard） 到新节点；

    数据迁移是在线的，但会有 slot 对应 key 的拷贝；

    迁移期间客户端可能需要重试（MOVED 重定向），系统复杂性增加。

3. Redis集群扩容痛点

| 问题      | 原因                                          |
| ------- | ------------------------------------------- |
| 数据迁移成本高 | 每个节点负责的槽必须移动，涉及大量 key 拷贝，耗 I/O              |
| 节点数不灵活  | Hash slot 固定 16384 个，节点过多时每个节点的槽数过少，导致负载不均衡 |
| 客户端路由复杂 | 扩容后客户端需要更新 slot 映射，否则会出现 MOVED 错误           |
| 扩容不透明   | 数据迁移期间可能影响性能，不能像 MQ 那样直接加 broker            |
| 不支持自动分区 | Redis Cluster 不像 Kafka 可以自动增加分区并平滑路由        |

4. 核心区别

| 维度     | Redis Cluster      | MQ (Kafka/RocketMQ)             |
| ------ | ------------------ | ------------------------------- |
| 分片机制   | Hash slot 固定 16384 | Partition 动态可扩                  |
| 扩容方式   | slot 重分布 + 数据迁移    | 增加 Broker + Partition 重分配       |
| 扩容代价   | 高（全量或大批量 key 迁移）   | 低（少量 Partition 迁移即可）            |
| 客户端透明度 | 低，需感知 MOVED        | 高，自动路由                          |
| 数据均衡   | 依赖 slot 迁移         | Partition + Consumer Group 自动均衡 |
| 动态扩展性  | 较弱                 | 很强                              |


### 5、Kafka如何实现幂等性和事务性语义
#### 幂等性实现机制（Idempotent Producer）
1. 实际配置
在0.11+版本后，只需要配置
```properties
enable.idempotence=true
```
2. 核心设计
每个 Producer 启动时都会被分配一个唯一的ProducerId，每个分区对应一个递增的SequenceNumber，当 Producer 向某个分区发送消息时，Kafka 发送的数据结构中包含：
```properties
ProducerId + Partition + SequenceNumber
```

3. Broker去重原理
Broker（具体是对应的 Partition Leader）会维护一个状态表：
```properties
<ProducerId, Partition> → lastSequenceNumber
```

当新的消息到达：

- 如果 SequenceNumber == lastSequenceNumber + 1 → ✅ 接受并更新；

- 如果 SequenceNumber <= lastSequenceNumber → 🚫 判定为重复消息，丢弃；

- 如果 SequenceNumber 跳号 → 表示消息丢失或乱序，Producer 会重新发送。

4. 幂等范围说明
Kafka 的幂等性是针对同一个 ProducerId + Partition 的有序写入。

#### 事务性语义（Exactly Once Semantics, EOS）
kafka的事务机制，是kafka实现端到端有且仅有一次语义的基础。Kafka 的 Exactly Once 幂等性只能保证单次会话内的精准一次性，不能解决跨会话和跨分区的问题；

Kafka的事务特性本质上是支持了Kafka跨分区和Topic的原子写操作。通过事务机制，KAFKA 可以实现对多个 topic 的多个 partition 的原子性的写入，即处于同一个事务内的所有消息，不管最终需要落地到哪个 topic 的哪个 partition, 最终结果都是要么全部写成功，要么全部写失败（Atomic multi-partition writes）；开启事务，必须开启幂等性，KAFKA的事务机制，在底层依赖于幂等生产者。

1. 配置启动
```properties
enable.idempotence=true
transactional.id=my-tx-id
```
2. 事务启动流程
Step 1：启动事务
```properties
producer.initTransactions();
producer.beginTransaction();
```
Step 2：生产消息（可跨多个 topic / partition）
```properties
enable.idempotence=true
transactional.id=my-tx-id
```
Step 3：绑定消费 offset

如果是流式消费（如 Kafka Streams），可以把消费 offset 一起提交到事务：
```properties
producer.sendOffsetsToTransaction(offsets, groupId);
```
Step 4：提交或回滚事务
```properties
producer.commitTransaction(); // 提交
// 或
producer.abortTransaction();  // 回滚

```
3. Transaction Coordinator 的作用
Kafka 集群中有专门的 Transaction Coordinator 管理事务元数据（写入 __transaction_state topic）：

- 记录事务状态（ongoing / commit / abort）

- 协调各分区提交或回滚

Producer 发送 COMMIT 时，Coordinator 会向所有参与分区写入 COMMIT_MARKER，只有当所有分区都成功标记后，事务才对外可见。

#### 面试总结回答（60 秒版本）
Kafka 的幂等性是通过为每个 Producer 分配唯一的 ProducerId，并在每个分区维护单调递增的 SequenceNumber 实现的。
Broker 会检测 SequenceNumber 是否连续，重复消息直接丢弃，从而实现幂等发送。

在此基础上，Kafka 引入 Transaction Coordinator 实现事务机制。
Producer 通过事务 ID 开启事务，将消息写入多个分区并在提交时统一写入提交标记；
Consumer 端设置 read_committed，只消费提交成功的事务数据。

最终实现 “Exactly Once Delivery”——不重复、不丢失、跨分区原子提交。

### 6. 为什么要用ES，而非别的方案
MySQL的劣势
传统方案的劣势：
| 问题              | 说明                                                                                 |
| --------------- | ---------------------------------------------------------------------------------- |
| **1. 索引维护复杂**   | 不同的查询条件组合太多（status + userId + type + expireTime…），MySQL 无法为每种组合建索引，导致频繁的索引回表和性能下降。 |
| **2. 模糊查询性能差**  | `LIKE '%couponName%'` 无法命中索引，全表扫描。                                                 |
| **3. 分页性能差**    | 当 offset 很大时（深分页），MySQL 要扫描大量无效行，`limit offset` 查询延迟高。                             |
| **4. QPS 承压**   | 高频读操作下，数据库连接、锁竞争、IO 都成为瓶颈。                                                         |
| **5. 数据热点**     | 某些用户/活动查询频繁，单节点容易成为热点。                                                             |
| **6. 无法支撑多维检索** | MySQL 只能基于有限索引组合查询，缺乏全文检索与多字段评分机制。                                                 |

ES的优势：
| 特点                | ES 的优势                                                            |
| ----------------- | ----------------------------------------------------------------- |
| **1. 支持多条件组合查询**  | ES 基于倒排索引（Inverted Index），可高效支持任意字段组合检索，不需要手动建多列索引。               |
| **2. 高性能模糊匹配**    | 内置分词器、模糊匹配、拼写纠错、前缀/通配符/正则查询等，适合运营侧灵活检索。                           |
| **3. 高并发读**       | ES 是分布式搜索引擎，数据分片后可水平扩展并行查询，天然支持高 QPS。                             |
| **4. 深分页优化**      | 支持 `search_after`、`scroll`、`point in time` 查询机制，解决 MySQL 深分页性能问题。 |
| **5. 统一查询入口**     | 可以将分散的营销、优惠券、活动等数据通过宽表聚合索引统一存储和查询。                                |
| **6. 可横向扩展**      | 可随数据量线性扩容，不影响已有查询逻辑。                                              |
| **7. 查询结果可排序和打分** | 支持 `_score`、多字段权重计算，可根据业务灵活定义排序逻辑。                                |
| **8. 与缓存结合良好**    | ES 自身带 segment-level cache、filter cache，可进一步减少 IO。                |

#### 为什么不用ClickHouse呢？

因为查询以“检索”为主，不是“分析”为主。
ClickHouse 是面向 OLAP 分析（聚合统计、报表计算），
而 Elasticsearch 是面向 检索查询（多维筛选、模糊匹配、实时响应）。

| 特性维度       | Elasticsearch                             | ClickHouse                             |
| ---------- | ----------------------------------------- | -------------------------------------- |
| **查询类型**   | 多条件检索、模糊搜索、分页、高并发读                        | 聚合分析、统计报表、批量计算                         |
| **典型场景**   | 用户搜索、后台筛选、实时查询接口                          | BI 报表、离线统计、看板汇总                        |
| **索引机制**   | 倒排索引（Inverted Index）                      | 列式存储（Column-oriented）                  |
| **查询语法**   | Bool 查询、term、match、range、fuzzy、wildcard 等 | SQL 风格，擅长 `GROUP BY`、`COUNT`、`SUM` 等聚合 |
| **分页性能**   | `search_after`、`scroll`，深分页性能优            | 深分页慢，需物化中间结果                           |
| **模糊匹配**   | 强（分词、模糊、拼写纠错）✅                            | 弱（like/regexp 性能差）❌                    |
| **延迟特征**   | 毫秒级实时响应                                   | 秒级批量查询                                 |
| **更新频率**   | 实时或准实时（1s 内刷新）                            | 批量写入，实时性较差                             |
| **写入代价**   | 较高（写入需构建倒排索引）                             | 写入轻（append-only）                       |
| **适用场景总结** | 检索型、高QPS查询                                | 分析型、聚合统计                               |

### 7. ES的按月来分表
``` json
PUT _index_template/coupon_template
{
  "index_patterns": ["coupon-2025-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "coupon_id": { "type": "keyword" },
        "user_id": { "type": "keyword" },
        "amount": { "type": "float" },
        "create_time": { "type": "date" }
      }
    }
  }
}



```

